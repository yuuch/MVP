{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import separate_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Phylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biom\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 'DOG_IDB'\n",
    "# test program\n",
    "try:\n",
    "    assert flag == 'test'\n",
    "    biom_path = 'upload_files/feature-table.biom'\n",
    "    tree_path = 'upload_files/tree.nwk'\n",
    "    metadata_path = 'upload_files/demo_metadata.tsv'\n",
    "    obj_col = 'BodySite'\n",
    "    SampleID = '#SampleID'\n",
    "except:\n",
    "    # DOG_IDB data\n",
    "    biom_path = 'Dog_IDB/all.biom'\n",
    "    tree_path = 'Dog_IDB/tree.nwk'\n",
    "    metadata_path = 'Dog_IDB/833_20180418-110621.txt'\n",
    "    obj_col = 'disease_stat'\n",
    "    SampleID = 'sample_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = biom.load_table(biom_path).to_dataframe().T.to_dense()\n",
    "old_df = old_df.divide(old_df.sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no #q2:types exist\n",
      "2828.4004859924316\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "mvp_tree = separate_tree.get_mvp_tree(biom_path,\\\n",
    "        tree_path,metadata_path)\n",
    "new_tic = time.time()\n",
    "# time used to gen mvp tree\n",
    "print(new_tic-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dog_idb_tree.pickle','wb') as f:\n",
    "    pickle.dump(mvp_tree,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_mvp_tree = copy.deepcopy(mvp_tree.feature_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_terminals_num = len(backup_mvp_tree.get_terminals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corr_tree_new\n",
    "import pandas as pd \n",
    "import copy \n",
    "import numpy as np \n",
    "import sklearn\n",
    "def get_terminal_length(tree):\n",
    "    terminal_lengths = {}\n",
    "    for terminal in tree.get_terminals():\n",
    "        path = tree.get_path(terminal)\n",
    "        TBL = 0 # terminal branch length\n",
    "        for ele in path:\n",
    "            TBL += ele.branch_length\n",
    "        terminal_lengths[terminal] = TBL\n",
    "    sorted_terminal = sorted(terminal_lengths,key=terminal_lengths.get,reverse=True)\n",
    "    sorted_terminal_lengths ={}\n",
    "    for ele in sorted_terminal:\n",
    "        sorted_terminal_lengths[ele] = terminal_lengths[ele]\n",
    "   # print(sorted_terminal_lengths)\n",
    "    return sorted_terminal_lengths\n",
    "\n",
    "def cut_tree(tree,cp=0.2):\n",
    "    \"\"\" \n",
    "    cut some branches of the tree.\n",
    "    return the pruned branches.\n",
    "    Args:\n",
    "        tree: a Phylo.tree object\n",
    "        cp: a percent used to cut the edge.\n",
    "    \"\"\"\n",
    "    cp = 1-cp\n",
    "    clades = []\n",
    "    const = 1 # limit the terminal of a subtree\n",
    "    terminal_lengths = get_terminal_length(tree)\n",
    "    for terminal in terminal_lengths:\n",
    "        current_terminals = tree.get_terminals()\n",
    "        if not terminal in current_terminals:\n",
    "            continue\n",
    "        threshold = terminal_lengths[terminal]*cp\n",
    "        temp = 0\n",
    "        path = tree.get_path(terminal)\n",
    "        for ele in path:\n",
    "            temp += ele.branch_length\n",
    "            if temp > threshold:\n",
    "                #if not ele in current_terminals:  \n",
    "                if len(ele.get_terminals()) > const:\n",
    "                    backup = copy.copy(ele)\n",
    "                    ele.clades = []\n",
    "                    clades.append(backup)\n",
    "                    try:\n",
    "                        ele_parent = tree.get_path(ele)[-2]\n",
    "                        ele_parent.clades.remove(ele)\n",
    "                    except:\n",
    "                        pass\n",
    "                break\n",
    "    return clades\n",
    "def recurse_to_update(node):\n",
    "    \"\"\"used in the update sample series function.\n",
    "    \"\"\"\n",
    "    if node.clades:\n",
    "        node.sample_series = copy.deepcopy(recurse_to_update(node.clades[0]))\n",
    "        for i,ele in enumerate(node.clades):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                node.sample_series += recurse_to_update(ele)\n",
    "    else:\n",
    "        return node.sample_series\n",
    "def recursion_tree(node):\n",
    "        \"\"\"recursion to get the sample_series of a tree\n",
    "        \"\"\"\n",
    "        if node.clades: # for non-leaf node\n",
    "            tmp = 0\n",
    "            flag = 0\n",
    "            for clade in node.clades:\n",
    "                if flag == 0:\n",
    "                    tmp = copy.copy(recursion_tree(clade).sample_series)\n",
    "                else:\n",
    "                    tmp += recursion_tree(clade).sample_series   \n",
    "                flag = 1\n",
    "            node.sample_series = tmp\n",
    "        else: # leaf node which has been init above.\n",
    "            try:\n",
    "                a = node.sample_series\n",
    "                #print(node.name +' is a leaf')\n",
    "            except:\n",
    "                print('please initialize the tree leaves by otu table.')\n",
    "        return node    \n",
    "def update_sample_series(tree):\n",
    "    \"\"\" update sample series after cut the tree.\n",
    "    Args:\n",
    "        tree: tree with sample_siries on the terminals.\n",
    "    \"\"\"\n",
    "    recursion_tree(tree)\n",
    "    #return tree\n",
    "    \n",
    "def get_mvp_tree(feature_table_path, tree_path, metadata_path):\n",
    "    mvp_tree = corr_tree_new.MvpTree(feature_table_path, tree_path, metadata_path)\n",
    "    return mvp_tree\n",
    "def sep_mvp_tree(mvp_tree,cp):\n",
    "    tree = copy.copy(mvp_tree.feature_tree)\n",
    "    sub_trees = cut_tree(tree,cp)\n",
    "    for ele in sub_trees:\n",
    "        ele = update_sample_series(ele)\n",
    "    print('len sub_trees:')\n",
    "    print(len(sub_trees))\n",
    "    return sub_trees\n",
    "\n",
    "def get_node_score(node,coef=[1,1,1]):\n",
    "    score = coef[0]*np.mean(node.sample_series)+\\\n",
    "        coef[1]*node.GI+coef[2]*np.std(node.sample_series)\n",
    "    return score     \n",
    "\n",
    "def search_sub_tree(sub_tree,coef,list1 = []):\n",
    "    #print('search_sub_tree')\n",
    "    p_score  = get_node_score(sub_tree,coef)\n",
    "    child_score = 0\n",
    "    for ele in sub_tree.clades:\n",
    "        child_score += get_node_score(ele,coef)\n",
    "    try:\n",
    "        child_score = child_score/len(sub_tree.clades)\n",
    "    except:\n",
    "        pass\n",
    "    if p_score <= child_score: \n",
    "        for ele in sub_tree.clades:\n",
    "            search_sub_tree(ele,coef,list1)\n",
    "    else:\n",
    "        list1.append(sub_tree)\n",
    "    #print('len list1')\n",
    "    #print(len(list1))\n",
    "    return list1\n",
    "\n",
    "    \n",
    "def generate_new_OTU_table(sub_trees,coef):\n",
    "    \"\"\"get a OTU table from the root node of the subtrees.\n",
    "    Args:\n",
    "        list1: obtained from the search_sub_tree function.\n",
    "        coef: used for compute the score function,e.g.[1,1,1]\n",
    "    \"\"\"\n",
    "    series = []\n",
    "    for sub_tree in sub_trees:\n",
    "        list1 = search_sub_tree(sub_tree,coef,list1=[])\n",
    "        for ele in list1:\n",
    "            series.append(ele.sample_series)\n",
    "    df = pd.DataFrame(series)\n",
    "    print('df.shape',df.shape)\n",
    "    #print('df.index.name',df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cp = 0.05\n",
    "coef = [1,200,1]\n",
    "sub_trees = sep_mvp_tree(mvp_tree,cp=cp)\n",
    "df = generate_new_OTU_table(sub_trees,coef).T\n",
    "mvp_tree.feature_tree =copy.deepcopy(backup_mvp_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3434"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mvp_tree.feature_tree.get_terminals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_path, sep= '\\t')\n",
    "\n",
    "metadata = metadata.set_index(SampleID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table_X = []\n",
    "feature_table_Y = []\n",
    "unpruned_clfs = {}\n",
    "for ele in mvp_tree.feature_table.T.index:\n",
    "    if metadata[obj_col][ele] == 'acute hem. diarrhea':\n",
    "        continue\n",
    "    feature_table_X.append(mvp_tree.feature_table.T.loc[ele])\n",
    "    feature_table_Y.append(metadata[obj_col][ele])\n",
    "            #clf = GradientBoostingClassifier(n_estimators=100,random_state=1) # 10 estimators 0.76 ,100 Ests 0.79\n",
    "#old_clf = RandomForestClassifier(n_estimators=100, random_state=1) # 20 Ests.0.77, 100 Ests 0.79\n",
    "            #clf = AdaBoostClassifier(random_state=1) # 0.73\n",
    "            #clf = MultinomialNB(alpha=1)\n",
    "#old_cv_result = cross_validate(old_clf,feature_table_X,feature_table_Y,cv=10,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table_X = np.array(feature_table_X)\n",
    "\n",
    "feature_table_Y = np.array(feature_table_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 3434)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf1 = StratifiedKFold(n_splits=10,random_state = 1)\n",
    "skf1.get_n_splits(feature_table_X,feature_table_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909117063492\n"
     ]
    }
   ],
   "source": [
    "old_clf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "aucs = []\n",
    "fprs = []\n",
    "tprs = []\n",
    "for train_index, test_index in skf1.split(feature_table_X,feature_table_Y):\n",
    "    X_train, X_test = feature_table_X[train_index], feature_table_X[test_index]\n",
    "    y_train, y_test = feature_table_Y[train_index], feature_table_Y[test_index]\n",
    "    old_clf.fit(X_train,y_train)\n",
    "    y_pred = old_clf.predict_proba(X_test)[:,1]\n",
    "    y_test = [[0,1][ele=='healthy'] for ele in y_test]\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test,y_pred)\n",
    "    fpr, tpr, _ = roc_curve(y_test,y_pred)\n",
    "    aucs.append(auc)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "print(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.76875000000000004,\n",
       " 0.86250000000000004,\n",
       " 0.94999999999999996,\n",
       " 0.84722222222222221,\n",
       " 0.86111111111111116,\n",
       " 0.92063492063492058,\n",
       " 1.0,\n",
       " 0.98412698412698418,\n",
       " 0.97619047619047616,\n",
       " 0.92063492063492069]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_table_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acute hem. diarrhea\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acute hem. diarrhea': 15, 'healthy': 98, 'IBD': 79}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = {}\n",
    "flag = True\n",
    "for ele in metadata[obj_col]:\n",
    "    if ele in categories:\n",
    "        categories[ele] += 1\n",
    "    else:\n",
    "        categories[ele] = 1\n",
    "    if ele == 'acute hem. diarrhea' and flag:\n",
    "        print(ele)\n",
    "        flag = False\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len sub_trees:\n",
      "161\n",
      "df.shape (170, 182)\n",
      "0.908898809524\n",
      "0.87512254902\n"
     ]
    }
   ],
   "source": [
    "#f = open('sep_mvp_result.txt','w')\n",
    "tic = time.time()\n",
    "cps = [0.08]\n",
    "#cps = [0.08]\n",
    "#[1,800,200]\n",
    "coefs = [#[1,20,1],\n",
    "         #[1,15,1],\n",
    "         #[1,10,7],\n",
    "         #[1,1,7],\n",
    "     #[1,1,10],\n",
    "    [2,6,13]\n",
    "     #[1,1,66]\n",
    "       ]\n",
    "acc_threshold = 0.5\n",
    "continue_flag = True\n",
    "cp_delta = 0.01\n",
    "deltas = [1,2,3]\n",
    "iter_num = 0\n",
    "# up down bounds used to constrain the cp(cut percent) value.\n",
    "up_bound = 0.15\n",
    "down_bound = 0.01\n",
    "# Max_key used to store the key.e.g str([0.08,1,20,1])\n",
    "Max_key = ''\n",
    "Last_Max_key = 'temp'\n",
    "results = {}\n",
    "#clfs = {}\n",
    "while continue_flag:\n",
    "    iter_num += 1\n",
    "    for cp in cps:\n",
    "        mvp_tree.feature_tree =copy.deepcopy(backup_mvp_tree)\n",
    "        if len(mvp_tree.feature_tree.get_terminals()) < init_terminals_num:\n",
    "            print('tree has been edited')\n",
    "            break\n",
    "        sub_trees = sep_mvp_tree(mvp_tree,cp=cp)\n",
    "        for coef in coefs:\n",
    "            if str([cp]+[coef]) in results:\n",
    "                continue\n",
    "            df = generate_new_OTU_table(sub_trees,coef).T\n",
    "            X = []\n",
    "            Y = []\n",
    "            if df.shape == (0,0):\n",
    "                continue\n",
    "            for ele in df.index:\n",
    "                if metadata[obj_col][ele] == 'acute hem. diarrhea':\n",
    "                    continue\n",
    "                X.append(df.loc[ele])\n",
    "                Y.append(metadata[obj_col][ele])\n",
    "            #clf = GradientBoostingClassifier(n_estimators=100,random_state=1) # 10 estimators 0.76 ,100 Ests 0.79\n",
    "            #clf = RandomForestClassifier(n_estimators=100, random_state=1) # 20 Ests.0.77, 100 Ests 0.79\n",
    "            #clf = AdaBoostClassifier(random_state=1) # 0.73\n",
    "            #clf = MultinomialNB(alpha=1)\n",
    "            #cv_result = cross_validate(clf,X,Y,cv=10,return_train_score=True)\n",
    "            \n",
    "            #temp_key = str([cp]+coef)\n",
    "            #clfs[temp_key] = clf\n",
    "            #results[temp_key]=cv_result\n",
    "            X = np.array(X)\n",
    "            y = np.array(Y)\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "            cut_aucs = []\n",
    "            cut_fprs = []\n",
    "            cut_tprs = []\n",
    "            accs = []\n",
    "            for train_index, test_index in skf.split(X,y):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                clf.fit(X_train,y_train)\n",
    "                y_pred_prob = clf.predict_proba(X_test)[:,0]\n",
    "                y_test = [[0,1][ele=='IBD'] for ele in y_test]\n",
    "                auc = sklearn.metrics.roc_auc_score(y_test,y_pred_prob)\n",
    "                y_pred = [[0,1][ele=='IBD'] for ele in clf.predict(X_test)]\n",
    "                fpr, tpr, _ = roc_curve(y_test,y_pred_prob)\n",
    "                cut_aucs.append(auc)\n",
    "                cut_fprs.append(fpr)\n",
    "                cut_tprs.append(tpr)\n",
    "                assert len(y_test) ==len(y_pred)\n",
    "                acc = sklearn.metrics.accuracy_score(y_pred,y_test)\n",
    "                accs.append(acc)\n",
    "            print(np.mean(cut_aucs))\n",
    "            print(np.mean(accs))\n",
    "    break\n",
    "    \"\"\"\n",
    "   \n",
    "    # generate new cps and coefs\n",
    "    for key in results:\n",
    "        if np.mean(results[key]['test_score']) > acc_threshold:\n",
    "            acc_threshold = np.mean(results[key]['test_score'])\n",
    "            Max_key = key\n",
    "        else:\n",
    "            pass\n",
    "    if Max_key == Last_Max_key:\n",
    "        print(Max_key)\n",
    "        break\n",
    "    Last_Max_key = copy.deepcopy(Max_key)\n",
    "    Max_key_list = [float(ele) for ele in Max_key[1:-1].split(', ')]\n",
    "    # update cps\n",
    "    cps  = [max(Max_key_list[0]-cp_delta,down_bound), Max_key_list[0], min(Max_key_list[0]+cp_delta,up_bound)]\n",
    "    # update coef\n",
    "    Max_key_list.remove(Max_key_list[0])\n",
    "    temps = [] # store paied coefs\n",
    "    for i,ele  in enumerate(Max_key_list):\n",
    "        temps.append([ele+deltas[i],ele-deltas[i]])\n",
    "    coefs = list(itertools.product(temps[0],temps[1],temps[2]))\n",
    "    coefs = [list(ele) for ele in coefs]\n",
    "    #coef.append(temp)\n",
    "    #print(results)\n",
    "    print('cps',cps)\n",
    "    print('coefs',coefs)\n",
    "print('iter_num:',iter_num)\n",
    "new_tic = time.time()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.86874999999999991,\n",
       " 0.85000000000000009,\n",
       " 0.90000000000000002,\n",
       " 0.86805555555555558,\n",
       " 0.84027777777777779,\n",
       " 0.92063492063492069,\n",
       " 1.0,\n",
       " 0.98412698412698407,\n",
       " 0.93650793650793651,\n",
       " 0.92063492063492069]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,random_state=1)\n",
    "skf.get_n_splits(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=3, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=1) \n",
    "#train_index,test_index = list(skf.split(X,Y))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test = X[train_index], X[test_index]\n",
    "#y_train, y_test = Y[train_index], Y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 132)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-661d84c436a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "pred_y =clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906160714286\n",
      "0.858455882353\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "cut_aucs = []\n",
    "cut_fprs = []\n",
    "cut_tprs = []\n",
    "accs = []\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:,0]\n",
    "    y_test = [[1,0][ele=='healthy'] for ele in y_test]\n",
    "    auc = sklearn.metrics.roc_auc_score(y_test,y_pred_prob)\n",
    "    y_pred = [[1,0][ele=='healthy'] for ele in clf.predict(X_test)]\n",
    "    fpr, tpr, _ = roc_curve(y_test,y_pred_prob)\n",
    "    cut_aucs.append(auc)\n",
    "    cut_fprs.append(fpr)\n",
    "    cut_tprs.append(tpr)\n",
    "    assert len(y_test) ==len(y_pred)\n",
    "    acc = sklearn.metrics.accuracy_score(y_pred,y_test)\n",
    "    accs.append(acc)\n",
    "print(np.mean(cut_aucs))\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [[-1,1][ele =='healthy'] for ele in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr,_ =sklearn.metrics.roc_curve(y_test, pred_y,pos_label=1,drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(y_test,pred_y)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total spend 16.20 minutes\n"
     ]
    }
   ],
   "source": [
    "print('total spend %.2f minutes' %((new_tic-tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87512254901960773"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results[Max_key]['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83333333,  0.88888889,  0.94444444,  0.88235294,  0.76470588,\n",
       "        0.8125    ,  1.        ,  0.9375    ,  0.875     ,  0.8125    ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[Max_key]['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.08, 2.0, 6.0, 13.0]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/core/numeric.py:2604: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ec9f4efe9122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Compute ROC curve and area the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtprs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \"\"\"\n\u001b[1;32m    612\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 613\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    409\u001b[0m              \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m              np.array_equal(classes, [1]))):\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=6)\n",
    "classifier = svm.SVC(kernel='linear', probability=True,\n",
    "                     random_state=random_state)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
